Implementations of all building blocks of a linear classifer and a neural network without using any built-in machine learning libraries. These implementations are mainly for learning purposes. 
The structure of some files follow the guidelines provided in Andrej Karpathy's CS231n 2016 course (http://cs231n.github.io/)


Some  of the components implemented
- Multi-class loss functions
- Various parameter update algorithms
- Forward and backward passes of multiple layers in a DNN
- Numerical and analytical gradient checking
- Fully connected NN
- Convolutional neural net layers
- Three layer CNN class

Still to come implementations
- few other bells and whistles for CNN


