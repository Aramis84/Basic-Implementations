Implementations of all building blocks of a linear classifer and a neural network without using any built-in machine learning libraries. These implementations are mainly for learning purposes.

Some  of the components implemented
- Multi-class loss functions
- Various parameter update algorithms
- Forward and backward passes of multiple layers in a DNN
- Numerical and analytical gradient checking

Still to come implementations
- Fully connected NN
- Testing with common datasets

